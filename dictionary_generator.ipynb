{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9534361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304c2e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
    "path_to_file = 'dictionary.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "475e7f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4478507"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(path_to_file , 'rb').read().decode(encoding = 'utf-8') # read and decode for py2 compat\n",
    "len(text)  # length in characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310d84ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-  prefix (also an- before a vowel sound) not, without (amoral). [greek]\n",
      "\n",
      "Aa  abbr. 1 automobile association. 2 alcoholics anonymous. 3 anti-aircraft.\n",
      "\n",
      "Aardvark  n. Mammal with a tubular snout and a long tongue, feeding on termites. [afrikaans]\n",
      "\n",
      "Ab-  prefix off, away, from (abduct). [latin]\n",
      "\n",
      "Aback  adv.  take aback surprise, disconcert. [old english: related to *a2]\n",
      "\n",
      "Abacus  n. (pl. -cuses) 1 frame with wires along which beads are slid for calculating. 2 archit. Flat slab on top of a capital. \n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4799c089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '\\n'),\n",
       " (1, ' '),\n",
       " (2, '!'),\n",
       " (3, '\"'),\n",
       " (4, '$'),\n",
       " (5, '%'),\n",
       " (6, '&'),\n",
       " (7, \"'\"),\n",
       " (8, '('),\n",
       " (9, ')'),\n",
       " (10, '*'),\n",
       " (11, '+'),\n",
       " (12, ','),\n",
       " (13, '-'),\n",
       " (14, '.'),\n",
       " (15, '/'),\n",
       " (16, '0'),\n",
       " (17, '1'),\n",
       " (18, '2'),\n",
       " (19, '3'),\n",
       " (20, '4'),\n",
       " (21, '5'),\n",
       " (22, '6'),\n",
       " (23, '7'),\n",
       " (24, '8'),\n",
       " (25, '9'),\n",
       " (26, ':'),\n",
       " (27, ';'),\n",
       " (28, '='),\n",
       " (29, '?'),\n",
       " (30, 'A'),\n",
       " (31, 'B'),\n",
       " (32, 'C'),\n",
       " (33, 'D'),\n",
       " (34, 'E'),\n",
       " (35, 'F'),\n",
       " (36, 'G'),\n",
       " (37, 'H'),\n",
       " (38, 'I'),\n",
       " (39, 'J'),\n",
       " (40, 'K'),\n",
       " (41, 'L'),\n",
       " (42, 'M'),\n",
       " (43, 'N'),\n",
       " (44, 'O'),\n",
       " (45, 'P'),\n",
       " (46, 'Q'),\n",
       " (47, 'R'),\n",
       " (48, 'S'),\n",
       " (49, 'T'),\n",
       " (50, 'U'),\n",
       " (51, 'V'),\n",
       " (52, 'W'),\n",
       " (53, 'X'),\n",
       " (54, 'Y'),\n",
       " (55, 'Z'),\n",
       " (56, '['),\n",
       " (57, ']'),\n",
       " (58, '^'),\n",
       " (59, '`'),\n",
       " (60, 'a'),\n",
       " (61, 'b'),\n",
       " (62, 'c'),\n",
       " (63, 'd'),\n",
       " (64, 'e'),\n",
       " (65, 'f'),\n",
       " (66, 'g'),\n",
       " (67, 'h'),\n",
       " (68, 'i'),\n",
       " (69, 'j'),\n",
       " (70, 'k'),\n",
       " (71, 'l'),\n",
       " (72, 'm'),\n",
       " (73, 'n'),\n",
       " (74, 'o'),\n",
       " (75, 'p'),\n",
       " (76, 'q'),\n",
       " (77, 'r'),\n",
       " (78, 's'),\n",
       " (79, 't'),\n",
       " (80, 'u'),\n",
       " (81, 'v'),\n",
       " (82, 'w'),\n",
       " (83, 'x'),\n",
       " (84, 'y'),\n",
       " (85, 'z'),\n",
       " (86, '{'),\n",
       " (87, '|'),\n",
       " (88, '}'),\n",
       " (89, '\\x7f'),\n",
       " (90, '£'),\n",
       " (91, '¨'),\n",
       " (92, '©'),\n",
       " (93, '®'),\n",
       " (94, '°'),\n",
       " (95, '´'),\n",
       " (96, 'À'),\n",
       " (97, 'Æ'),\n",
       " (98, 'É'),\n",
       " (99, '×'),\n",
       " (100, 'à'),\n",
       " (101, 'á'),\n",
       " (102, 'â'),\n",
       " (103, 'ä'),\n",
       " (104, 'å'),\n",
       " (105, 'æ'),\n",
       " (106, 'ç'),\n",
       " (107, 'è'),\n",
       " (108, 'é'),\n",
       " (109, 'ê'),\n",
       " (110, 'í'),\n",
       " (111, 'î'),\n",
       " (112, 'ï'),\n",
       " (113, 'ñ'),\n",
       " (114, 'ó'),\n",
       " (115, 'ô'),\n",
       " (116, 'ö'),\n",
       " (117, '÷'),\n",
       " (118, 'ø'),\n",
       " (119, 'ú'),\n",
       " (120, 'û'),\n",
       " (121, 'ü'),\n",
       " (122, 'Œ'),\n",
       " (123, 'œ'),\n",
       " (124, 'ˆ'),\n",
       " (125, '˜'),\n",
       " (126, '–'),\n",
       " (127, '—'),\n",
       " (128, '‘'),\n",
       " (129, '’'),\n",
       " (130, '“'),\n",
       " (131, '”'),\n",
       " (132, '†'),\n",
       " (133, '…')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(text))  # creating mapping from characters to integers\n",
    "\n",
    "list(enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03719423",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))  # creating mapping from characters to integers\n",
    "char_to_index = {c:i for i, c in enumerate(vocab)}\n",
    "index_to_char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text) :\n",
    "    return np.array([char_to_index[i] for i in text])\n",
    "\n",
    "int_text = text_to_int(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4572997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-  prefix (also an-\n",
      "[30 13  1  1 75 77 64 65 68 83  1  8 60 71 78 74  1 60 73 13]\n"
     ]
    }
   ],
   "source": [
    "print(text[:20])\n",
    "print(int_text[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6252871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-  prefix (also an-\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints) :\n",
    "    try :\n",
    "        ints = ints.numpy()\n",
    "    except :\n",
    "        pass\n",
    "    return ''.join(index_to_char[ints])\n",
    "\n",
    "print(int_to_text(int_text[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d574e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100  # training example sequence length\n",
    "examples_per_epoch = len(text) // (SEQ_LENGTH + 1) \n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(int_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc1816c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(SEQ_LENGTH + 1, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a0821d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk) :  # takes 'hello'\n",
    "    input_text = chunk[:-1]      # 'hell'\n",
    "    target_text = chunk[1:]      # 'ello'\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)  # applies function to every entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20052acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Start>\n",
      "<Input>\n",
      "A-  prefix (also an- before a vowel sound) not, without (amoral). [greek]\n",
      "\n",
      "Aa  abbr. 1 automobile as\n",
      "<Output>\n",
      "-  prefix (also an- before a vowel sound) not, without (amoral). [greek]\n",
      "\n",
      "Aa  abbr. 1 automobile ass\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(1) :\n",
    "    print('<Start>')\n",
    "    print('<Input>')\n",
    "    print(int_to_text(x))\n",
    "    print('<Output>')\n",
    "    print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7649b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "# buffer is how much is suffled in ram at a time, because of possibly enormous sequences\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "104153ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size) :\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size,\n",
    "                                  embedding_dim,\n",
    "                                  batch_input_shape = [batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                             return_sequences = True,\n",
    "                             stateful = True,\n",
    "                             recurrent_initializer = 'glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2cff402",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abc34229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           34304     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 134)           137350    \n",
      "=================================================================\n",
      "Total params: 5,418,630\n",
      "Trainable params: 5,418,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9798fbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 134) (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1) :\n",
    "    example_batch_predictions = model(input_example_batch) # ask model for prediction on first batch\n",
    "    print(example_batch_predictions.shape, '(batch_size, sequence_length, vocab_size)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24e90b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[-4.7523309e-03 -2.6344325e-04 -2.3887385e-04 ...  4.9010678e-03\n",
      "   -3.4105496e-03  3.4125438e-03]\n",
      "  [-4.3406356e-03  3.5034172e-04 -1.1831223e-03 ...  8.9563290e-03\n",
      "    7.2912691e-04  2.2232374e-03]\n",
      "  [-2.4334961e-03  9.5190684e-04 -7.0881522e-03 ...  9.5284078e-03\n",
      "   -6.0752919e-04  3.6943443e-03]\n",
      "  ...\n",
      "  [ 2.3143031e-03  5.8845007e-03 -8.2875378e-03 ...  4.7474117e-03\n",
      "    4.0495303e-03 -1.0548484e-03]\n",
      "  [-2.7498598e-03  3.6736934e-03 -6.2989444e-03 ...  8.0564441e-03\n",
      "    5.3704524e-04  3.2046498e-03]\n",
      "  [-2.6359521e-03  2.7193914e-03 -5.6223380e-03 ...  1.0985430e-02\n",
      "    4.4924514e-03  2.6371062e-03]]\n",
      "\n",
      " [[-2.5919313e-03  3.8523525e-03  2.6125318e-04 ... -2.3118665e-03\n",
      "    6.1819406e-04 -3.9751166e-03]\n",
      "  [-1.9999431e-03  4.8030019e-03 -6.1301654e-03 ...  1.5240270e-03\n",
      "   -7.0604717e-04 -4.7459180e-04]\n",
      "  [ 4.0071756e-03  3.1684779e-03 -3.4246102e-03 ...  2.3305619e-03\n",
      "    1.9699833e-03  4.1584144e-03]\n",
      "  ...\n",
      "  [-7.6922299e-03  3.1561996e-03 -1.0147181e-03 ...  1.2161552e-02\n",
      "    4.2247041e-03 -4.9282946e-03]\n",
      "  [-4.9549132e-03  1.9446117e-03 -9.2823803e-04 ...  1.5801087e-02\n",
      "    6.9560218e-03 -3.9928402e-03]\n",
      "  [ 4.5899618e-03 -2.8804685e-03 -4.7145179e-05 ...  1.5182236e-02\n",
      "    8.0675157e-03 -4.0721414e-03]]\n",
      "\n",
      " [[-7.0724217e-04  7.7478559e-04 -4.5191980e-04 ...  4.9503897e-03\n",
      "    3.9302940e-03  5.6553763e-05]\n",
      "  [ 9.3931204e-04  8.2243985e-04  3.7394979e-03 ...  5.6971535e-03\n",
      "    4.7307229e-05  2.1195302e-03]\n",
      "  [ 2.3000054e-03  1.8631746e-03 -3.8668700e-03 ...  5.3262138e-03\n",
      "   -9.2355459e-04  2.8758685e-03]\n",
      "  ...\n",
      "  [ 3.6035657e-03 -3.1529025e-03  5.9112324e-04 ...  7.6732724e-03\n",
      "    6.9149854e-03 -3.4240136e-04]\n",
      "  [-1.6076117e-03 -4.4214510e-04 -1.1805694e-03 ...  1.0157768e-02\n",
      "    5.5357404e-03 -4.5257467e-03]\n",
      "  [-2.8969101e-03 -3.1127878e-03  6.3635007e-04 ...  8.3129928e-03\n",
      "    3.2119008e-03 -1.0694895e-03]]], shape=(3, 100, 134), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(len(example_batch_predictions))  \n",
    "# prediction is 64 100 character probability lists, 65 characters per\n",
    "print(example_batch_predictions[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3671144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[-0.00475233 -0.00026344 -0.00023887 ...  0.00490107 -0.00341055\n",
      "   0.00341254]\n",
      " [-0.00434064  0.00035034 -0.00118312 ...  0.00895633  0.00072913\n",
      "   0.00222324]\n",
      " [-0.0024335   0.00095191 -0.00708815 ...  0.00952841 -0.00060753\n",
      "   0.00369434]\n",
      " ...\n",
      " [ 0.0023143   0.0058845  -0.00828754 ...  0.00474741  0.00404953\n",
      "  -0.00105485]\n",
      " [-0.00274986  0.00367369 -0.00629894 ...  0.00805644  0.00053705\n",
      "   0.00320465]\n",
      " [-0.00263595  0.00271939 -0.00562234 ...  0.01098543  0.00449245\n",
      "   0.00263711]], shape=(100, 134), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc419198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[-4.7523309e-03 -2.6344325e-04 -2.3887385e-04  8.0332253e-03\n",
      " -4.8806812e-03 -7.2714505e-03 -1.5418846e-03  1.6831834e-04\n",
      "  1.1657855e-03  3.6409583e-03  4.5705698e-03  1.8087268e-03\n",
      " -2.5830022e-03  2.6997674e-05 -1.1343315e-03 -1.0301720e-03\n",
      "  6.0899311e-04  5.3959647e-03 -1.5546158e-03  1.0036178e-03\n",
      "  1.5036254e-03 -1.1157946e-03  5.0069438e-03 -2.3691957e-03\n",
      " -5.4780608e-03  3.1098283e-03 -7.5391395e-04 -1.9625307e-03\n",
      "  6.0769161e-03  2.6672373e-03 -2.3814826e-04  2.5046158e-03\n",
      "  5.5898293e-03 -1.4186408e-03  4.2247954e-03 -3.1643626e-04\n",
      " -1.1529793e-03  4.5659118e-03  5.9198178e-03 -1.3465105e-03\n",
      " -5.8210311e-03 -1.6400469e-03 -3.4029961e-03  1.9173344e-03\n",
      "  2.1601305e-04  9.6979673e-04 -2.5303019e-03  4.5640289e-04\n",
      " -2.2754961e-04  2.9184441e-03  5.6587736e-04 -9.3462918e-04\n",
      "  2.6601120e-03  4.8241829e-03  8.0416712e-04  2.4302937e-03\n",
      "  7.6320139e-04 -4.4557150e-03  6.4576562e-03 -1.7228216e-03\n",
      " -2.0587606e-05  6.8564457e-03 -3.8646389e-04  2.4021361e-03\n",
      " -1.7684863e-04 -3.0034864e-03 -3.0698352e-03 -2.0021386e-03\n",
      " -4.5725820e-03  2.6703484e-03  7.5764494e-04 -2.7780882e-03\n",
      "  2.4813781e-03 -1.6706444e-03 -1.8720740e-03 -1.2732005e-03\n",
      " -4.7670426e-03  4.0953034e-03 -3.4037564e-04  2.3697315e-04\n",
      " -6.7751325e-04 -3.3234404e-03  1.9105877e-03  7.9375822e-03\n",
      "  2.3019230e-03  9.1432780e-04 -1.5046331e-03  5.2236253e-03\n",
      " -1.8140569e-04 -3.2959771e-03 -3.6672147e-03  6.8244361e-03\n",
      "  1.1937284e-03  8.5567241e-04 -6.0849991e-03 -2.1411877e-03\n",
      " -6.3435946e-05 -6.6715502e-04  4.3749134e-03  6.5501226e-04\n",
      " -3.6074894e-03 -5.1314984e-03  4.3413211e-03 -7.5905770e-04\n",
      " -1.6974808e-03 -8.0997432e-03  1.1782625e-03 -3.2366728e-04\n",
      "  1.6545651e-03  1.9513200e-03 -4.7190399e-03 -1.8657756e-04\n",
      " -2.0487790e-03 -2.9591476e-03  5.5251666e-03 -1.7383631e-03\n",
      "  2.7475816e-03 -1.4330704e-03 -1.6445417e-03 -2.3626126e-04\n",
      " -2.8836271e-03  5.0027259e-03  3.6646132e-04 -2.8923326e-03\n",
      "  5.3716626e-04  2.2988637e-04  1.2584012e-03 -6.2981300e-04\n",
      "  2.4457814e-03  8.9437347e-03  4.9894964e-03  4.9010678e-03\n",
      " -3.4105496e-03  3.4125438e-03], shape=(134,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "time_pred = pred[0]\n",
    "print(len(pred))\n",
    "print(time_pred)  # the 65 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "826d1a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 34]\n",
      " [ 93]\n",
      " [129]\n",
      " [109]\n",
      " [ 42]\n",
      " [  0]\n",
      " [ 88]\n",
      " [ 78]\n",
      " [ 86]\n",
      " [ 22]], shape=(10, 1), dtype=int64)\n",
      "[ 34  93 129 109  42   0  88  78  86  22   1   7  34  13 125   5  92  33\n",
      "  57   1  84  29   1  94  91  73  83  26  30  67  76  54  86  17 116   6\n",
      "  24   5  67  17  17  49  13 122  79 102   5  41 126  41 115 111  70 130\n",
      " 116 107  68  86 105  14 107  82  35  14  38  51  91  27  53 128 131   1\n",
      "  51  96  96  69  66  95   8 127  34 112 120  33  96 107  48  62  17  55\n",
      "  56  42  11  37  68  57  11  11  26  80]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"E®’êM\\n}s{6 'E-˜%©D] y? °¨nx:AhqY{1ö&8%h11T-Œtâ%L–Lôîk“öèi{æ.èwF.IV¨;X‘” VÀÀjg´(—EïûDÀèSc1Z[M+Hi]++:u\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample output distribution, turn array of character probabilities into single character prediction\n",
    "sampled_integers = tf.random.categorical(pred, num_samples = 1)\n",
    "print(sampled_integers[:10])\n",
    "# reshape array, convert arrays of integers to integer array for character processing\n",
    "sampled_integers = np.reshape(sampled_integers, (1, -1))[0]\n",
    "print(sampled_integers)\n",
    "predicted_chars = int_to_text(sampled_integers)\n",
    "\n",
    "predicted_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5e3aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits) :\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4221474",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b625c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model checkpoints to directory\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# name of checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix,\n",
    "                                                         save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77d8bcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "692/692 [==============================] - 33s 47ms/step - loss: 1.6298\n",
      "Epoch 2/3\n",
      "692/692 [==============================] - 33s 47ms/step - loss: 1.4635\n",
      "Epoch 3/3\n",
      "692/692 [==============================] - 33s 47ms/step - loss: 1.3777\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, epochs = 10, callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20bfbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('shakespeare.h5')\n",
    "# loaded_model = tf.keras.models.load_model('cats_dogs.h5')\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55397d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5fabde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('dictionary.m5')\n",
    "# model = tf.keras.models.load_model('dictionary.m5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cf9f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string) :\n",
    "    # generate text using learned model\n",
    "    num_generate = 1000  # number of characters to generate\n",
    "    # convert start string to numbers (vectorizing)\n",
    "    input_eval = text_to_int(start_string)\n",
    "    input_eval = tf.expand_dims(input_eval, 0) # put int list into a 1 item list to mimic batches\n",
    "    \n",
    "    text_generated = []  # empty list to store results\n",
    "    \n",
    "    temperature = 1.0  # low temps = more predictable text, high temps = more surprising text\n",
    "    # batch size will be 1\n",
    "    model.reset_states()  # get rid of LSTM memory\n",
    "    \n",
    "    for i in range(num_generate) :\n",
    "        predictions = model(input_eval)\n",
    "        # remove outside fluff list dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # use categorical distribution to predict character returned by model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1, 0].numpy()\n",
    "        # pass predicted character as next input to model along with previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(index_to_char[predicted_id])\n",
    "    \n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a40d2fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting string: Beachelous -v\n",
      "Beachelous -versted) 1 (as roman idly, metallic, or recroim, madeculary. 2 (of a greature's sheat) a person's rashed in a wall. 2 constable round (banking many; treatury etc.).  vehicle adj.\n",
      "\n",
      "Unimp  v. 1 (also abble) coace from which the starbons, rain. 2 (often foll. By to + infin.) Be one's kind that price. 3 asstonic. (withdown).\n",
      "WTy ears victure than below anmost sore for fueur englishmptur. [anglo-fresh too eggn]\n",
      "\n",
      "Terminism  n. (pl. Symbodium or most) 1 treatment. [old english]\n",
      "\n",
      "Whee-appear  after sleen who or is woman children lay  n. Bloof with a producing animal. 2 universibly shoet.  desiringly adv. [perhatic pictivise]\n",
      "\n",
      "Events  adj. (fingr. Take happeniated) occernment to a yeud.\n",
      "\n",
      "Wetter2  n. (pl. -ies) 1 tattland sion. [old english]\n",
      "\n",
      "Speed  —n. 1 tim of penesual jack, ess or offence in a branch, news and indian.\n",
      "\n",
      "Unread  v. (-ging) 1 person who years (safe, or family or persimal orge with a present knowledge.\n",
      "\n",
      "Undour-hode  n. Colloq. Count of a roof by a pail. 3 performation, much thin\n"
     ]
    }
   ],
   "source": [
    "inp = input('Starting string: ')\n",
    "print(generate_text(model, inp))  # enter seed text for text generation :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15955d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
