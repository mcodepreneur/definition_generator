{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9534361b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304c2e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = 'dictionary.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "475e7f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4478507"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open(path_to_file , 'rb').read().decode(encoding = 'utf-8') # read and decode for py2 compat\n",
    "len(text)  # length in characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "310d84ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-  prefix (also an- before a vowel sound) not, without (amoral). [greek]\n",
      "\n",
      "Aa  abbr. 1 automobile association. 2 alcoholics anonymous. 3 anti-aircraft.\n",
      "\n",
      "Aardvark  n. Mammal with a tubular snout and a long tongue, feeding on termites. [afrikaans]\n",
      "\n",
      "Ab-  prefix off, away, from (abduct). [latin]\n",
      "\n",
      "Aback  adv.  take aback surprise, disconcert. [old english: related to *a2]\n",
      "\n",
      "Abacus  n. (pl. -cuses) 1 frame with wires along which beads are slid for calculating. 2 archit. Flat slab on top of a capital. \n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4799c089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '\\n'),\n",
       " (1, ' '),\n",
       " (2, '!'),\n",
       " (3, '\"'),\n",
       " (4, '$'),\n",
       " (5, '%'),\n",
       " (6, '&'),\n",
       " (7, \"'\"),\n",
       " (8, '('),\n",
       " (9, ')'),\n",
       " (10, '*'),\n",
       " (11, '+'),\n",
       " (12, ','),\n",
       " (13, '-'),\n",
       " (14, '.'),\n",
       " (15, '/'),\n",
       " (16, '0'),\n",
       " (17, '1'),\n",
       " (18, '2'),\n",
       " (19, '3'),\n",
       " (20, '4'),\n",
       " (21, '5'),\n",
       " (22, '6'),\n",
       " (23, '7'),\n",
       " (24, '8'),\n",
       " (25, '9'),\n",
       " (26, ':'),\n",
       " (27, ';'),\n",
       " (28, '='),\n",
       " (29, '?'),\n",
       " (30, 'A'),\n",
       " (31, 'B'),\n",
       " (32, 'C'),\n",
       " (33, 'D'),\n",
       " (34, 'E'),\n",
       " (35, 'F'),\n",
       " (36, 'G'),\n",
       " (37, 'H'),\n",
       " (38, 'I'),\n",
       " (39, 'J'),\n",
       " (40, 'K'),\n",
       " (41, 'L'),\n",
       " (42, 'M'),\n",
       " (43, 'N'),\n",
       " (44, 'O'),\n",
       " (45, 'P'),\n",
       " (46, 'Q'),\n",
       " (47, 'R'),\n",
       " (48, 'S'),\n",
       " (49, 'T'),\n",
       " (50, 'U'),\n",
       " (51, 'V'),\n",
       " (52, 'W'),\n",
       " (53, 'X'),\n",
       " (54, 'Y'),\n",
       " (55, 'Z'),\n",
       " (56, '['),\n",
       " (57, ']'),\n",
       " (58, '^'),\n",
       " (59, '`'),\n",
       " (60, 'a'),\n",
       " (61, 'b'),\n",
       " (62, 'c'),\n",
       " (63, 'd'),\n",
       " (64, 'e'),\n",
       " (65, 'f'),\n",
       " (66, 'g'),\n",
       " (67, 'h'),\n",
       " (68, 'i'),\n",
       " (69, 'j'),\n",
       " (70, 'k'),\n",
       " (71, 'l'),\n",
       " (72, 'm'),\n",
       " (73, 'n'),\n",
       " (74, 'o'),\n",
       " (75, 'p'),\n",
       " (76, 'q'),\n",
       " (77, 'r'),\n",
       " (78, 's'),\n",
       " (79, 't'),\n",
       " (80, 'u'),\n",
       " (81, 'v'),\n",
       " (82, 'w'),\n",
       " (83, 'x'),\n",
       " (84, 'y'),\n",
       " (85, 'z'),\n",
       " (86, '{'),\n",
       " (87, '|'),\n",
       " (88, '}'),\n",
       " (89, '\\x7f'),\n",
       " (90, '£'),\n",
       " (91, '¨'),\n",
       " (92, '©'),\n",
       " (93, '®'),\n",
       " (94, '°'),\n",
       " (95, '´'),\n",
       " (96, 'À'),\n",
       " (97, 'Æ'),\n",
       " (98, 'É'),\n",
       " (99, '×'),\n",
       " (100, 'à'),\n",
       " (101, 'á'),\n",
       " (102, 'â'),\n",
       " (103, 'ä'),\n",
       " (104, 'å'),\n",
       " (105, 'æ'),\n",
       " (106, 'ç'),\n",
       " (107, 'è'),\n",
       " (108, 'é'),\n",
       " (109, 'ê'),\n",
       " (110, 'í'),\n",
       " (111, 'î'),\n",
       " (112, 'ï'),\n",
       " (113, 'ñ'),\n",
       " (114, 'ó'),\n",
       " (115, 'ô'),\n",
       " (116, 'ö'),\n",
       " (117, '÷'),\n",
       " (118, 'ø'),\n",
       " (119, 'ú'),\n",
       " (120, 'û'),\n",
       " (121, 'ü'),\n",
       " (122, 'Œ'),\n",
       " (123, 'œ'),\n",
       " (124, 'ˆ'),\n",
       " (125, '˜'),\n",
       " (126, '–'),\n",
       " (127, '—'),\n",
       " (128, '‘'),\n",
       " (129, '’'),\n",
       " (130, '“'),\n",
       " (131, '”'),\n",
       " (132, '†'),\n",
       " (133, '…')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(text))  # creating mapping from characters to integers\n",
    "\n",
    "list(enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03719423",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))  # creating mapping from characters to integers\n",
    "char_to_index = {c:i for i, c in enumerate(vocab)}\n",
    "index_to_char = np.array(vocab)\n",
    "\n",
    "def text_to_int(text) :\n",
    "    return np.array([char_to_index[i] for i in text])\n",
    "\n",
    "int_text = text_to_int(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4572997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-  prefix (also an-\n",
      "[30 13  1  1 75 77 64 65 68 83  1  8 60 71 78 74  1 60 73 13]\n"
     ]
    }
   ],
   "source": [
    "print(text[:20])\n",
    "print(int_text[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6252871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-  prefix (also an-\n"
     ]
    }
   ],
   "source": [
    "def int_to_text(ints) :\n",
    "    try :\n",
    "        ints = ints.numpy()\n",
    "    except :\n",
    "        pass\n",
    "    return ''.join(index_to_char[ints])\n",
    "\n",
    "print(int_to_text(int_text[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d574e64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 100  # training example sequence length\n",
    "examples_per_epoch = len(text) // (SEQ_LENGTH + 1) \n",
    "\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(int_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc1816c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(SEQ_LENGTH + 1, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a0821d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk) :  # takes 'hello'\n",
    "    input_text = chunk[:-1]      # 'hell'\n",
    "    target_text = chunk[1:]      # 'ello'\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)  # applies function to every entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20052acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Start>\n",
      "<Input>\n",
      "A-  prefix (also an- before a vowel sound) not, without (amoral). [greek]\n",
      "\n",
      "Aa  abbr. 1 automobile as\n",
      "<Output>\n",
      "-  prefix (also an- before a vowel sound) not, without (amoral). [greek]\n",
      "\n",
      "Aa  abbr. 1 automobile ass\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataset.take(1) :\n",
    "    print('<Start>')\n",
    "    print('<Input>')\n",
    "    print(int_to_text(x))\n",
    "    print('<Output>')\n",
    "    print(int_to_text(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7649b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "VOCAB_SIZE = len(vocab)\n",
    "EMBEDDING_DIM = 256\n",
    "RNN_UNITS = 1024\n",
    "# buffer is how much is suffled in ram at a time, because of possibly enormous sequences\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "data = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "104153ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size) :\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size,\n",
    "                                  embedding_dim,\n",
    "                                  batch_input_shape = [batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                             return_sequences = True,\n",
    "                             stateful = True,\n",
    "                             recurrent_initializer = 'glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2cff402",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abc34229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           34304     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 1024)          5246976   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 134)           137350    \n",
      "=================================================================\n",
      "Total params: 5,418,630\n",
      "Trainable params: 5,418,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9798fbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 134) (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in data.take(1) :\n",
    "    example_batch_predictions = model(input_example_batch) # ask model for prediction on first batch\n",
    "    print(example_batch_predictions.shape, '(batch_size, sequence_length, vocab_size)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24e90b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "tf.Tensor(\n",
      "[[[-2.71745352e-03 -1.18277955e-03 -6.32086943e-04 ... -1.89054047e-03\n",
      "    1.61831221e-03 -9.50910558e-04]\n",
      "  [-6.21750439e-03 -5.92403114e-04 -7.63355708e-03 ... -4.10511019e-03\n",
      "    2.29516299e-03 -2.09119497e-03]\n",
      "  [-8.17770418e-03 -5.58275788e-04 -1.22253178e-02 ... -6.73481729e-03\n",
      "    2.29908852e-03 -2.37179175e-03]\n",
      "  ...\n",
      "  [-1.49231181e-02  1.59795978e-03 -3.93226696e-03 ... -3.28733237e-03\n",
      "    1.13530608e-03  7.39269378e-03]\n",
      "  [-1.00096790e-02  6.71566417e-03 -1.74557976e-03 ... -6.36397395e-03\n",
      "    4.32780152e-03  1.13998251e-02]\n",
      "  [-6.20333105e-03  1.65863510e-03  5.19932387e-03 ... -8.58087372e-03\n",
      "    7.91321415e-03  3.99046624e-03]]\n",
      "\n",
      " [[-4.34833230e-04 -4.25370922e-03  5.03918994e-03 ... -3.03444942e-03\n",
      "    5.71694039e-03 -5.68087073e-03]\n",
      "  [-3.55223683e-03 -3.37840407e-03 -2.67904042e-03 ... -5.54943690e-03\n",
      "    4.45361668e-03 -5.76314190e-03]\n",
      "  [-5.70843974e-03 -5.01964102e-03  2.16631731e-03 ...  9.28945665e-05\n",
      "    2.13573733e-03 -6.30031666e-03]\n",
      "  ...\n",
      "  [-5.83231729e-03 -1.17886026e-04 -3.02458578e-03 ... -8.15009791e-03\n",
      "    6.03115140e-03  1.75859630e-02]\n",
      "  [-6.32075733e-03 -5.12091070e-03 -3.16030986e-04 ... -8.49388633e-03\n",
      "    5.03274053e-03  1.89847015e-02]\n",
      "  [-1.33168995e-02 -9.20729188e-04 -4.27732430e-03 ... -2.93213339e-03\n",
      "    3.39797721e-03  1.35890311e-02]]\n",
      "\n",
      " [[-3.72786401e-03 -1.95165107e-03  3.33065260e-03 ...  4.77462169e-03\n",
      "    2.14434549e-05 -2.60622846e-03]\n",
      "  [-2.70146341e-03 -5.01722330e-03 -1.18157675e-03 ...  2.04450940e-03\n",
      "   -1.53560145e-03  2.87351082e-03]\n",
      "  [ 4.32485627e-04  1.50440319e-05 -3.23200668e-03 ...  4.78511536e-03\n",
      "   -6.20423304e-03  9.06024710e-04]\n",
      "  ...\n",
      "  [-7.17887329e-03 -3.27902567e-03 -1.99311250e-03 ... -1.78003050e-02\n",
      "    3.13544297e-03  1.41437044e-02]\n",
      "  [-1.01201599e-02 -4.77828644e-03  2.38272408e-03 ... -9.27502755e-03\n",
      "    1.39925035e-03  8.92423932e-03]\n",
      "  [-1.33165410e-02 -5.24548441e-03 -1.90132472e-04 ... -4.76386352e-03\n",
      "    3.94204026e-03  1.32725779e-02]]], shape=(3, 100, 134), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(len(example_batch_predictions))  \n",
    "# prediction is 64 100 character probability lists, 65 characters per\n",
    "print(example_batch_predictions[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3671144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[[-0.00271745 -0.00118278 -0.00063209 ... -0.00189054  0.00161831\n",
      "  -0.00095091]\n",
      " [-0.0062175  -0.0005924  -0.00763356 ... -0.00410511  0.00229516\n",
      "  -0.00209119]\n",
      " [-0.0081777  -0.00055828 -0.01222532 ... -0.00673482  0.00229909\n",
      "  -0.00237179]\n",
      " ...\n",
      " [-0.01492312  0.00159796 -0.00393227 ... -0.00328733  0.00113531\n",
      "   0.00739269]\n",
      " [-0.01000968  0.00671566 -0.00174558 ... -0.00636397  0.0043278\n",
      "   0.01139983]\n",
      " [-0.00620333  0.00165864  0.00519932 ... -0.00858087  0.00791321\n",
      "   0.00399047]], shape=(100, 134), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "pred = example_batch_predictions[0]\n",
    "print(len(pred))\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc419198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "tf.Tensor(\n",
      "[-2.7174535e-03 -1.1827796e-03 -6.3208694e-04  7.5204240e-04\n",
      "  1.4312178e-03  3.6873259e-03 -1.7914982e-03 -8.1829894e-03\n",
      " -4.1323388e-03  4.2588916e-04 -1.6987163e-03  4.9392353e-03\n",
      "  4.3502864e-03 -2.0654986e-03  1.2768402e-03  2.2119319e-03\n",
      " -3.2099709e-03 -2.7290205e-03 -3.3001979e-03  3.6570828e-03\n",
      "  2.9047283e-03 -4.1215739e-04  2.9001255e-03 -5.4370724e-03\n",
      "  1.4014631e-03 -9.8939671e-04 -5.5363611e-03 -1.7483592e-03\n",
      " -4.0845079e-03  2.3842275e-03  3.1268462e-03 -1.6331309e-03\n",
      " -4.2570938e-04  1.9226820e-03  2.1457628e-05 -1.4045604e-03\n",
      "  3.7953602e-03  2.7737552e-03 -2.4732414e-03  2.9089756e-03\n",
      "  6.0451124e-03  1.8080318e-05  2.8850909e-03 -2.7214163e-03\n",
      " -4.9044588e-03  3.5660891e-03  5.6260214e-03 -8.4308377e-03\n",
      " -4.1912752e-04  2.6489072e-04 -1.2152259e-03  2.1309834e-03\n",
      "  2.8660423e-03 -3.9911104e-04 -3.3040373e-03  1.5886924e-03\n",
      "  1.9148778e-03 -8.9831930e-03  1.1089224e-03  2.3875632e-03\n",
      "  3.2780988e-03  4.4541014e-03 -3.3685673e-04 -2.8182822e-03\n",
      " -5.4626823e-03 -3.5383694e-03 -3.2384286e-03  1.1625576e-05\n",
      " -2.2988245e-03 -3.4948410e-03 -5.3452300e-03  4.0461537e-03\n",
      " -2.5603052e-03  3.4334443e-03  3.7226737e-03 -7.4872209e-05\n",
      " -5.1844134e-03 -2.9731421e-03 -5.2818158e-03 -2.6331607e-03\n",
      " -2.5108273e-03  4.9761869e-04 -5.7510040e-03  7.7471486e-07\n",
      " -3.2340640e-03  1.8416011e-03  5.8122713e-04  1.0367385e-04\n",
      "  4.6026059e-03  2.2013260e-03 -1.4304467e-03  5.2177748e-03\n",
      "  6.8733175e-03  3.0242087e-04 -3.2407297e-03 -3.4041533e-03\n",
      " -3.4699501e-03 -3.6762841e-03  1.0289970e-02  6.0898997e-04\n",
      "  4.9187457e-03  8.3077268e-04 -5.2905055e-03  2.6386473e-03\n",
      " -2.0827528e-03 -9.4876776e-04 -3.0951104e-03 -1.3675651e-03\n",
      " -3.2370824e-03  3.2635971e-03  3.6544076e-04 -1.4776106e-04\n",
      " -1.9654888e-04 -1.4022893e-03 -1.2105969e-03 -2.2051726e-04\n",
      "  1.4069304e-03 -2.9750958e-03  3.8586063e-03  3.2579468e-03\n",
      " -3.5986619e-03 -2.2428667e-03  1.3951196e-03 -6.7448705e-03\n",
      " -5.4081320e-03 -3.5902490e-03  3.2902844e-03 -3.5657142e-03\n",
      " -2.8107364e-03 -4.4920053e-03  1.1767294e-03 -1.8905405e-03\n",
      "  1.6183122e-03 -9.5091056e-04], shape=(134,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "time_pred = pred[0]\n",
    "print(len(pred))\n",
    "print(time_pred)  # the 65 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "826d1a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[109]\n",
      " [ 30]\n",
      " [ 79]\n",
      " [ 64]\n",
      " [ 83]\n",
      " [ 28]\n",
      " [109]\n",
      " [ 15]\n",
      " [ 74]\n",
      " [ 35]], shape=(10, 1), dtype=int64)\n",
      "[109  30  79  64  83  28 109  15  74  35  47  51  93  31  39  56  25 110\n",
      " 128  66  66  31  57 114   8  82   8  12 133  99 125   5  83  92  95  73\n",
      "  47  67  60  72  36 103  18  77 124 122   0  87  75  22 106  95 127   1\n",
      "   8  19  69  35  90  34  25 101  35  12 110  57  85 120 108 120   3 106\n",
      "  69  78  52  78  24 109  22  66  98  10  99   5 123  73 104  34  82  87\n",
      "  11   1  51  90 102   2  98  15  83   1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'êAtex=ê/oFRV®BJ[9í‘ggB]ó(w(,…×˜%x©´nRhamGä2rˆŒ\\n|p6ç´— (3jF£E9áF,í]zûéû\"çjsWs8ê6gÉ*×%œnåEw|+ V£â!É/x '"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample output distribution, turn array of character probabilities into single character prediction\n",
    "sampled_integers = tf.random.categorical(pred, num_samples = 1)\n",
    "print(sampled_integers[:10])\n",
    "# reshape array, convert arrays of integers to integer array for character processing\n",
    "sampled_integers = np.reshape(sampled_integers, (1, -1))[0]\n",
    "print(sampled_integers)\n",
    "predicted_chars = int_to_text(sampled_integers)\n",
    "\n",
    "predicted_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5e3aba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits) :\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4221474",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b625c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model checkpoints to directory\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# name of checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = checkpoint_prefix,\n",
    "                                                         save_weights_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77d8bcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "692/692 [==============================] - 44s 58ms/step - loss: 2.0677\n",
      "Epoch 2/10\n",
      "692/692 [==============================] - 41s 59ms/step - loss: 1.5106\n",
      "Epoch 3/10\n",
      "692/692 [==============================] - 44s 63ms/step - loss: 1.3770\n",
      "Epoch 4/10\n",
      "692/692 [==============================] - 41s 58ms/step - loss: 1.3018\n",
      "Epoch 5/10\n",
      "692/692 [==============================] - 43s 62ms/step - loss: 1.2503\n",
      "Epoch 6/10\n",
      "692/692 [==============================] - 40s 58ms/step - loss: 1.2098\n",
      "Epoch 7/10\n",
      "692/692 [==============================] - 40s 57ms/step - loss: 1.1764\n",
      "Epoch 8/10\n",
      "692/692 [==============================] - 40s 58ms/step - loss: 1.1473\n",
      "Epoch 9/10\n",
      "692/692 [==============================] - 40s 58ms/step - loss: 1.1218\n",
      "Epoch 10/10\n",
      "692/692 [==============================] - 49s 71ms/step - loss: 1.0987\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data, epochs = 10, callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20bfbe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('shakespeare.h5')\n",
    "# loaded_model = tf.keras.models.load_model('cats_dogs.h5')\n",
    "model = build_model(VOCAB_SIZE, EMBEDDING_DIM, RNN_UNITS, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55397d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a5fabde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('dictionary.m5')\n",
    "# model = tf.keras.models.load_model('dictionary.m5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cf9f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string) :\n",
    "    # generate text using learned model\n",
    "    num_generate = 1000  # number of characters to generate\n",
    "    # convert start string to numbers (vectorizing)\n",
    "    input_eval = text_to_int(start_string)\n",
    "    input_eval = tf.expand_dims(input_eval, 0) # put int list into a 1 item list to mimic batches\n",
    "    \n",
    "    text_generated = []  # empty list to store results\n",
    "    \n",
    "    temperature = 1.0  # low temps = more predictable text, high temps = more surprising text\n",
    "    # batch size will be 1\n",
    "    model.reset_states()  # get rid of LSTM memory\n",
    "    \n",
    "    for i in range(num_generate) :\n",
    "        predictions = model(input_eval)\n",
    "        # remove outside fluff list dimension\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # use categorical distribution to predict character returned by model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples = 1)[-1, 0].numpy()\n",
    "        # pass predicted character as next input to model along with previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(index_to_char[predicted_id])\n",
    "    \n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a40d2fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting string: Apple\n",
      "Applep)Baching a person's life of oxbolize (looped has turn). —n. 1 watchbands from ntatric acid. [french]\n",
      "\n",
      "Spanki  n. (pl. -s) grass term with a fipse rings structurally, e.g. The riot terms up. 13 (of a top player) act or treat (a state etc.) Fluff. 5 bid out of a motorwise substance used to small use. 2 a electromability aid etc. B (attrib.) Non-slasting group. B marriageable terminated buttle. 2 person who strikes orig. A weapon. —v. (-ting) 1 assk with a twig or rock (a country). 2 turn important. 9 (usu. Foll. By on) be trudged and lugged on. 3 constrain from another's action.\n",
      "\n",
      "Undercust  colloq. —adv. Archaic or not soundworth interest or arrangement; reve with). 7 (foll. By on) depart by enemy of the impatiency or testedship. 2 the lustrots. 2 quantity of conditions or activities etc. In vapour. [origin unknown]\n",
      "\n",
      "Unknown sterling, esp. Not reprinant.\n",
      "\n",
      "Unworry  adj. (-ier, -iest). 3 hollow wordsake, royal, i during war as word-blue.  wear repertory  n. 1 impudent in sense 2, fortune\n"
     ]
    }
   ],
   "source": [
    "inp = input('Starting string: ')\n",
    "print(generate_text(model, inp))  # enter seed text for text generation :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15955d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
